{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Merging and Joining**\n",
    "1. **Inner Join on Chinook Database**\n",
    "   - Load the `chinook.db` database.\n",
    "   - Perform an inner join between the `customers` and `invoices` tables on the `CustomerId` column.\n",
    "   - Find the total number of invoices for each customer.\n"
   ],
   "id": "9c56e59722d2747f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:54:25.646550Z",
     "start_time": "2025-04-09T09:54:22.191187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "with sqlite3.connect('data/chinook.db') as connection:\n",
    "    customers = pd.read_sql(\"select * from customers\", connection)\n",
    "    invoices = pd.read_sql(\"select * from invoices\", connection)\n",
    "    print(customers.merge(invoices, on='CustomerId'))\n"
   ],
   "id": "e3934fe6b9ac4574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CustomerId FirstName    LastName  \\\n",
      "0             1      Luís   Gonçalves   \n",
      "1             1      Luís   Gonçalves   \n",
      "2             1      Luís   Gonçalves   \n",
      "3             1      Luís   Gonçalves   \n",
      "4             1      Luís   Gonçalves   \n",
      "..          ...       ...         ...   \n",
      "407          59      Puja  Srivastava   \n",
      "408          59      Puja  Srivastava   \n",
      "409          59      Puja  Srivastava   \n",
      "410          59      Puja  Srivastava   \n",
      "411          59      Puja  Srivastava   \n",
      "\n",
      "                                              Company  \\\n",
      "0    Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "1    Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "2    Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "3    Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "4    Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "..                                                ...   \n",
      "407                                              None   \n",
      "408                                              None   \n",
      "409                                              None   \n",
      "410                                              None   \n",
      "411                                              None   \n",
      "\n",
      "                             Address                 City State Country  \\\n",
      "0    Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP  Brazil   \n",
      "1    Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP  Brazil   \n",
      "2    Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP  Brazil   \n",
      "3    Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP  Brazil   \n",
      "4    Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP  Brazil   \n",
      "..                               ...                  ...   ...     ...   \n",
      "407                3,Raj Bhavan Road            Bangalore  None   India   \n",
      "408                3,Raj Bhavan Road            Bangalore  None   India   \n",
      "409                3,Raj Bhavan Road            Bangalore  None   India   \n",
      "410                3,Raj Bhavan Road            Bangalore  None   India   \n",
      "411                3,Raj Bhavan Road            Bangalore  None   India   \n",
      "\n",
      "    PostalCode               Phone  ...                     Email  \\\n",
      "0    12227-000  +55 (12) 3923-5555  ...      luisg@embraer.com.br   \n",
      "1    12227-000  +55 (12) 3923-5555  ...      luisg@embraer.com.br   \n",
      "2    12227-000  +55 (12) 3923-5555  ...      luisg@embraer.com.br   \n",
      "3    12227-000  +55 (12) 3923-5555  ...      luisg@embraer.com.br   \n",
      "4    12227-000  +55 (12) 3923-5555  ...      luisg@embraer.com.br   \n",
      "..         ...                 ...  ...                       ...   \n",
      "407     560001    +91 080 22289999  ...  puja_srivastava@yahoo.in   \n",
      "408     560001    +91 080 22289999  ...  puja_srivastava@yahoo.in   \n",
      "409     560001    +91 080 22289999  ...  puja_srivastava@yahoo.in   \n",
      "410     560001    +91 080 22289999  ...  puja_srivastava@yahoo.in   \n",
      "411     560001    +91 080 22289999  ...  puja_srivastava@yahoo.in   \n",
      "\n",
      "    SupportRepId  InvoiceId          InvoiceDate  \\\n",
      "0              3         98  2010-03-11 00:00:00   \n",
      "1              3        121  2010-06-13 00:00:00   \n",
      "2              3        143  2010-09-15 00:00:00   \n",
      "3              3        195  2011-05-06 00:00:00   \n",
      "4              3        316  2012-10-27 00:00:00   \n",
      "..           ...        ...                  ...   \n",
      "407            3         45  2009-07-08 00:00:00   \n",
      "408            3         97  2010-02-26 00:00:00   \n",
      "409            3        218  2011-08-20 00:00:00   \n",
      "410            3        229  2011-09-30 00:00:00   \n",
      "411            3        284  2012-05-30 00:00:00   \n",
      "\n",
      "                      BillingAddress          BillingCity BillingState  \\\n",
      "0    Av. Brigadeiro Faria Lima, 2170  São José dos Campos           SP   \n",
      "1    Av. Brigadeiro Faria Lima, 2170  São José dos Campos           SP   \n",
      "2    Av. Brigadeiro Faria Lima, 2170  São José dos Campos           SP   \n",
      "3    Av. Brigadeiro Faria Lima, 2170  São José dos Campos           SP   \n",
      "4    Av. Brigadeiro Faria Lima, 2170  São José dos Campos           SP   \n",
      "..                               ...                  ...          ...   \n",
      "407                3,Raj Bhavan Road            Bangalore         None   \n",
      "408                3,Raj Bhavan Road            Bangalore         None   \n",
      "409                3,Raj Bhavan Road            Bangalore         None   \n",
      "410                3,Raj Bhavan Road            Bangalore         None   \n",
      "411                3,Raj Bhavan Road            Bangalore         None   \n",
      "\n",
      "    BillingCountry BillingPostalCode  Total  \n",
      "0           Brazil         12227-000   3.98  \n",
      "1           Brazil         12227-000   3.96  \n",
      "2           Brazil         12227-000   5.94  \n",
      "3           Brazil         12227-000   0.99  \n",
      "4           Brazil         12227-000   1.98  \n",
      "..             ...               ...    ...  \n",
      "407          India            560001   5.94  \n",
      "408          India            560001   1.99  \n",
      "409          India            560001   1.98  \n",
      "410          India            560001  13.86  \n",
      "411          India            560001   8.91  \n",
      "\n",
      "[412 rows x 21 columns]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. **Outer Join on Movie Data**\n",
    "   - Load the `movie.csv` file.\n",
    "   - Create two smaller DataFrames:\n",
    "     - One with only `director_name` and `color`.\n",
    "     - Another with `director_name` and `num_critic_for_reviews`.\n",
    "   - Perform a left join and then a full outer join on `director_name`.\n",
    "   - Count how many rows are in the resulting DataFrames for each join type.\n"
   ],
   "id": "c839d9a0f81df5cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:54:33.577252Z",
     "start_time": "2025-04-09T09:54:32.676925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movie_db = pd.read_csv('data/movie.csv')\n",
    "color = movie_db[['director_name', 'color']]\n",
    "reviews = movie_db[['director_name', 'num_critic_for_reviews']]\n",
    "left_join = color.merge(reviews, on='director_name', how='left')\n",
    "print(left_join)\n",
    "print(len(left_join))\n",
    "full_outer_join = color.merge(reviews, on='director_name', how='outer')\n",
    "print(full_outer_join)\n",
    "print(len(full_outer_join))"
   ],
   "id": "95955dd01ff8b288",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          director_name  color  num_critic_for_reviews\n",
      "0         James Cameron  Color                   723.0\n",
      "1         James Cameron  Color                   315.0\n",
      "2         James Cameron  Color                   210.0\n",
      "3         James Cameron  Color                    94.0\n",
      "4         James Cameron  Color                    82.0\n",
      "...                 ...    ...                     ...\n",
      "30295  Benjamin Roberds  Color                    13.0\n",
      "30296       Daniel Hsia  Color                    14.0\n",
      "30297          Jon Gunn  Color                    11.0\n",
      "30298          Jon Gunn  Color                    15.0\n",
      "30299          Jon Gunn  Color                    43.0\n",
      "\n",
      "[30300 rows x 3 columns]\n",
      "30300\n",
      "         director_name  color  num_critic_for_reviews\n",
      "0        A. Raven Cruz  Color                     3.0\n",
      "1           Aaron Hann  Color                    29.0\n",
      "2      Aaron Schneider  Color                   160.0\n",
      "3        Aaron Seltzer  Color                    99.0\n",
      "4         Abel Ferrara  Color                    48.0\n",
      "...                ...    ...                     ...\n",
      "30295              NaN  Color                    75.0\n",
      "30296              NaN  Color                    11.0\n",
      "30297              NaN  Color                    23.0\n",
      "30298              NaN  Color                    11.0\n",
      "30299              NaN  Color                    43.0\n",
      "\n",
      "[30300 rows x 3 columns]\n",
      "30300\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Grouping and Aggregating**\n",
    "1. **Grouped Aggregations on Titanic**\n",
    "   - Group passengers by `Pclass` and calculate the following:\n",
    "     - Average age.\n",
    "     - Total fare.\n",
    "     - Count of passengers.\n",
    "   - Save the results to a new DataFrame.\n"
   ],
   "id": "e644f51151bada5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:54:39.737004Z",
     "start_time": "2025-04-09T09:54:38.376581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_titanic = pd.read_excel('data/titanic.xlsx')\n",
    "grouped_df = df_titanic.groupby('Pclass').agg(\n",
    "    average_age=('Age', 'mean'),\n",
    "    total_fare=('Fare', 'sum'),\n",
    "    passenger_count=('PassengerId', 'count')\n",
    ").reset_index()\n",
    "print(grouped_df)"
   ],
   "id": "39b62a1d3d33d308",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  average_age  total_fare  passenger_count\n",
      "0       1    38.233441  18177.4125              216\n",
      "1       2    29.877630   3801.8417              184\n",
      "2       3    25.140620   6714.6951              491\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. **Multi-level Grouping on Movie Data**\n",
    "   - Group the movies by `color` and `director_name`.\n",
    "   - Find:\n",
    "     - Total `num_critic_for_reviews` for each group.\n",
    "     - Average `duration` for each group.\n"
   ],
   "id": "a54c9479bffc77f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:54:44.349125Z",
     "start_time": "2025-04-09T09:54:44.266103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_movie = movie_db.groupby(['color', 'director_name']).agg(\n",
    "    total_num_critic_for_reviews = ('num_critic_for_reviews', 'count'),\n",
    "    average_duration = ('duration', 'mean')\n",
    ").reset_index()\n",
    "print(grouped_movie)"
   ],
   "id": "c36ad7b59cf7204b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                color       director_name  total_num_critic_for_reviews  \\\n",
      "0     Black and White      Akira Kurosawa                             1   \n",
      "1     Black and White      Aleksey German                             1   \n",
      "2     Black and White        Alex Garland                             1   \n",
      "3     Black and White     Alexander Payne                             1   \n",
      "4     Black and White    Alfred Hitchcock                             2   \n",
      "...               ...                 ...                           ...   \n",
      "2485            Color       Zoran Lisinac                             1   \n",
      "2486            Color  Álex de la Iglesia                             1   \n",
      "2487            Color    Émile Gaudreault                             1   \n",
      "2488            Color        Éric Tessier                             1   \n",
      "2489            Color       Étienne Faure                             1   \n",
      "\n",
      "      average_duration  \n",
      "0                202.0  \n",
      "1                177.0  \n",
      "2                108.0  \n",
      "3                115.0  \n",
      "4                119.0  \n",
      "...                ...  \n",
      "2485             108.0  \n",
      "2486             104.0  \n",
      "2487              92.0  \n",
      "2488              99.0  \n",
      "2489              98.0  \n",
      "\n",
      "[2490 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. **Nested Grouping on Flights**\n",
    "   - Group flights by `Year` and `Month` and calculate:\n",
    "     - Total number of flights.\n",
    "     - Average arrival delay (`ArrDelay`).\n",
    "     - Maximum departure delay (`DepDelay`).\n"
   ],
   "id": "863c293a952e6bfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T10:31:32.238557Z",
     "start_time": "2025-04-09T10:30:51.558415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flights = pd.read_parquet('data/flights')\n",
    "grouped_flights = flights.groupby(['Year', 'Month']).agg(\n",
    "    total_num_flights=('Year', 'count'),\n",
    "    average_arr_delay = ('ArrDelay', 'mean'),\n",
    "    max_dep_delay=('DepDelay', 'max')\n",
    "\n",
    ").reset_index()\n",
    "print(grouped_flights)"
   ],
   "id": "2953088a6b125f9",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.46 GiB for an array with shape (109, 6729125) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mMemoryError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m flights = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdata/flights\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m grouped_flights = flights.groupby([\u001B[33m'\u001B[39m\u001B[33mYear\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mMonth\u001B[39m\u001B[33m'\u001B[39m]).agg(\n\u001B[32m      3\u001B[39m     total_num_flights=(\u001B[33m'\u001B[39m\u001B[33mYear\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mcount\u001B[39m\u001B[33m'\u001B[39m),\n\u001B[32m      4\u001B[39m     average_arr_delay = (\u001B[33m'\u001B[39m\u001B[33mArrDelay\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m'\u001B[39m),\n\u001B[32m      5\u001B[39m     max_dep_delay=(\u001B[33m'\u001B[39m\u001B[33mDepDelay\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mmax\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      6\u001B[39m \n\u001B[32m      7\u001B[39m ).reset_index()\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(grouped_flights)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001B[39m, in \u001B[36mread_parquet\u001B[39m\u001B[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[39m\n\u001B[32m    664\u001B[39m     use_nullable_dtypes = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    665\u001B[39m check_dtype_backend(dtype_backend)\n\u001B[32m--> \u001B[39m\u001B[32m667\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    668\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    669\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    670\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    671\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    672\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    673\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    674\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    675\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    676\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parquet.py:281\u001B[39m, in \u001B[36mPyArrowImpl.read\u001B[39m\u001B[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001B[39m\n\u001B[32m    273\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    274\u001B[39m     pa_table = \u001B[38;5;28mself\u001B[39m.api.parquet.read_table(\n\u001B[32m    275\u001B[39m         path_or_handle,\n\u001B[32m    276\u001B[39m         columns=columns,\n\u001B[32m   (...)\u001B[39m\u001B[32m    279\u001B[39m         **kwargs,\n\u001B[32m    280\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m281\u001B[39m     result = \u001B[43mpa_table\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mto_pandas_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    283\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m manager == \u001B[33m\"\u001B[39m\u001B[33marray\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    284\u001B[39m         result = result._as_manager(\u001B[33m\"\u001B[39m\u001B[33marray\u001B[39m\u001B[33m\"\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\array.pxi:889\u001B[39m, in \u001B[36mpyarrow.lib._PandasConvertible.to_pandas\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\table.pxi:5132\u001B[39m, in \u001B[36mpyarrow.lib.Table._to_pandas\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\pandas_compat.py:808\u001B[39m, in \u001B[36mtable_to_dataframe\u001B[39m\u001B[34m(options, table, categories, ignore_metadata, types_mapper)\u001B[39m\n\u001B[32m    805\u001B[39m columns = _deserialize_column_index(table, all_columns, column_indexes)\n\u001B[32m    807\u001B[39m column_names = table.column_names\n\u001B[32m--> \u001B[39m\u001B[32m808\u001B[39m result = \u001B[43mpa\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtable_to_blocks\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    809\u001B[39m \u001B[43m                                \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mext_columns_dtypes\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    810\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _pandas_api.is_ge_v3():\n\u001B[32m    811\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapi\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01minternals\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_dataframe_from_blocks\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\table.pxi:4061\u001B[39m, in \u001B[36mpyarrow.lib.table_to_blocks\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\error.pxi:89\u001B[39m, in \u001B[36mpyarrow.lib.check_status\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mMemoryError\u001B[39m: Unable to allocate 5.46 GiB for an array with shape (109, 6729125) and data type object"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### **Applying Functions**\n",
    "1. **Apply a Custom Function on Titanic**\n",
    "   - Write a function to classify passengers as `Child` (age < 18) or `Adult`.\n",
    "   - Use `apply` to create a new column, `Age_Group`, with these values.\n"
   ],
   "id": "3e098d8ec0626945"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:54:56.356961Z",
     "start_time": "2025-04-09T09:54:56.329081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def age_group(x):\n",
    "    if x < 18:\n",
    "        return 'Child'\n",
    "    return 'Adult'\n",
    "df_titanic['Age group'] = df_titanic['Age'].apply(age_group)\n",
    "print(df_titanic)"
   ],
   "id": "1587a2afc2a8d231",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked Age group  \n",
      "0        0         A/5 21171   7.2500   NaN        S     Adult  \n",
      "1        0          PC 17599  71.2833   C85        C     Adult  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S     Adult  \n",
      "3        0            113803  53.1000  C123        S     Adult  \n",
      "4        0            373450   8.0500   NaN        S     Adult  \n",
      "..     ...               ...      ...   ...      ...       ...  \n",
      "886      0            211536  13.0000   NaN        S     Adult  \n",
      "887      0            112053  30.0000   B42        S     Adult  \n",
      "888      2        W./C. 6607  23.4500   NaN        S     Adult  \n",
      "889      0            111369  30.0000  C148        C     Adult  \n",
      "890      0            370376   7.7500   NaN        Q     Adult  \n",
      "\n",
      "[891 rows x 13 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. **Normalize Employee Salaries**\n",
    "   - Load the `employee.csv` file.\n",
    "   - Normalize the salaries within each department.\n"
   ],
   "id": "30ef80c95aa4587a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:55:00.616073Z",
     "start_time": "2025-04-09T09:55:00.448167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "employees = pd.read_csv('data/employee.csv')\n",
    "employees"
   ],
   "id": "6e88d1e2f6fe804c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      UNIQUE_ID               POSITION_TITLE                     DEPARTMENT  \\\n",
       "0             0  ASSISTANT DIRECTOR (EX LVL)    Municipal Courts Department   \n",
       "1             1            LIBRARY ASSISTANT                        Library   \n",
       "2             2               POLICE OFFICER  Houston Police Department-HPD   \n",
       "3             3            ENGINEER/OPERATOR  Houston Fire Department (HFD)   \n",
       "4             4                  ELECTRICIAN    General Services Department   \n",
       "...         ...                          ...                            ...   \n",
       "1995       1995               POLICE OFFICER  Houston Police Department-HPD   \n",
       "1996       1996       COMMUNICATIONS CAPTAIN  Houston Fire Department (HFD)   \n",
       "1997       1997               POLICE OFFICER  Houston Police Department-HPD   \n",
       "1998       1998               POLICE OFFICER  Houston Police Department-HPD   \n",
       "1999       1999                 FIRE FIGHTER  Houston Fire Department (HFD)   \n",
       "\n",
       "      BASE_SALARY                       RACE EMPLOYMENT_TYPE  GENDER  \\\n",
       "0        121862.0            Hispanic/Latino       Full Time  Female   \n",
       "1         26125.0            Hispanic/Latino       Full Time  Female   \n",
       "2         45279.0                      White       Full Time    Male   \n",
       "3         63166.0                      White       Full Time    Male   \n",
       "4         56347.0                      White       Full Time    Male   \n",
       "...           ...                        ...             ...     ...   \n",
       "1995      43443.0                      White       Full Time    Male   \n",
       "1996      66523.0  Black or African American       Full Time    Male   \n",
       "1997      43443.0                      White       Full Time    Male   \n",
       "1998      55461.0     Asian/Pacific Islander       Full Time    Male   \n",
       "1999      51194.0            Hispanic/Latino       Full Time    Male   \n",
       "\n",
       "     EMPLOYMENT_STATUS   HIRE_DATE    JOB_DATE  \n",
       "0               Active  2006-06-12  2012-10-13  \n",
       "1               Active  2000-07-19  2010-09-18  \n",
       "2               Active  2015-02-03  2015-02-03  \n",
       "3               Active  1982-02-08  1991-05-25  \n",
       "4               Active  1989-06-19  1994-10-22  \n",
       "...                ...         ...         ...  \n",
       "1995            Active  2014-06-09  2015-06-09  \n",
       "1996            Active  2003-09-02  2013-10-06  \n",
       "1997            Active  2014-10-13  2015-10-13  \n",
       "1998            Active  2009-01-20  2011-07-02  \n",
       "1999            Active  2009-01-12  2010-07-12  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUE_ID</th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EMPLOYMENT_STATUS</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>Active</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>2012-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LIBRARY ASSISTANT</td>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>Active</td>\n",
       "      <td>2000-07-19</td>\n",
       "      <td>2010-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>1982-02-08</td>\n",
       "      <td>1991-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ELECTRICIAN</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>1989-06-19</td>\n",
       "      <td>1994-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2015-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>COMMUNICATIONS CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>66523.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>2003-09-02</td>\n",
       "      <td>2013-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>2015-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>55461.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>2011-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>51194.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>Active</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T10:04:04.235926Z",
     "start_time": "2025-04-09T10:04:04.161851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "employees['normalized_salary'] = employees.groupby('DEPARTMENT')['BASE_SALARY'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "print(employees)"
   ],
   "id": "1f13950fb1ed5c09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UNIQUE_ID               POSITION_TITLE                     DEPARTMENT  \\\n",
      "0             0  ASSISTANT DIRECTOR (EX LVL)    Municipal Courts Department   \n",
      "1             1            LIBRARY ASSISTANT                        Library   \n",
      "2             2               POLICE OFFICER  Houston Police Department-HPD   \n",
      "3             3            ENGINEER/OPERATOR  Houston Fire Department (HFD)   \n",
      "4             4                  ELECTRICIAN    General Services Department   \n",
      "...         ...                          ...                            ...   \n",
      "1995       1995               POLICE OFFICER  Houston Police Department-HPD   \n",
      "1996       1996       COMMUNICATIONS CAPTAIN  Houston Fire Department (HFD)   \n",
      "1997       1997               POLICE OFFICER  Houston Police Department-HPD   \n",
      "1998       1998               POLICE OFFICER  Houston Police Department-HPD   \n",
      "1999       1999                 FIRE FIGHTER  Houston Fire Department (HFD)   \n",
      "\n",
      "      BASE_SALARY                       RACE EMPLOYMENT_TYPE  GENDER  \\\n",
      "0        121862.0            Hispanic/Latino       Full Time  Female   \n",
      "1         26125.0            Hispanic/Latino       Full Time  Female   \n",
      "2         45279.0                      White       Full Time    Male   \n",
      "3         63166.0                      White       Full Time    Male   \n",
      "4         56347.0                      White       Full Time    Male   \n",
      "...           ...                        ...             ...     ...   \n",
      "1995      43443.0                      White       Full Time    Male   \n",
      "1996      66523.0  Black or African American       Full Time    Male   \n",
      "1997      43443.0                      White       Full Time    Male   \n",
      "1998      55461.0     Asian/Pacific Islander       Full Time    Male   \n",
      "1999      51194.0            Hispanic/Latino       Full Time    Male   \n",
      "\n",
      "     EMPLOYMENT_STATUS   HIRE_DATE    JOB_DATE  normalized_salary  \n",
      "0               Active  2006-06-12  2012-10-13           1.000000  \n",
      "1               Active  2000-07-19  2010-09-18           0.000000  \n",
      "2               Active  2015-02-03  2015-02-03           0.116351  \n",
      "3               Active  1982-02-08  1991-05-25           0.192491  \n",
      "4               Active  1989-06-19  1994-10-22           0.479189  \n",
      "...                ...         ...         ...                ...  \n",
      "1995            Active  2014-06-09  2015-06-09           0.105837  \n",
      "1996            Active  2003-09-02  2013-10-06           0.210879  \n",
      "1997            Active  2014-10-13  2015-10-13           0.105837  \n",
      "1998            Active  2009-01-20  2011-07-02           0.174655  \n",
      "1999            Active  2009-01-12  2010-07-12           0.126914  \n",
      "\n",
      "[2000 rows x 11 columns]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. **Custom Function on Movies**\n",
    "   - Write a function that returns `Short`, `Medium`, or `Long` based on the duration of a movie:\n",
    "     - `Short`: Less than 60 minutes.\n",
    "     - `Medium`: Between 60 and 120 minutes.\n",
    "     - `Long`: More than 120 minutes.\n",
    "   - Apply this function to classify movies in the `movie.csv` dataset.\n"
   ],
   "id": "6dfef57b855e4265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T10:07:40.842156Z",
     "start_time": "2025-04-09T10:07:40.696149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_movie_duration(x):\n",
    "    \"\"\"classifies movie according to its duration: Short, Medium, Long\"\"\"\n",
    "    if x < 60:\n",
    "        return 'Short'\n",
    "    elif x <= 120:\n",
    "        return 'Medium'\n",
    "    return 'Long'\n",
    "\n",
    "movie_db['classified_duration'] = movie_db['duration'].apply(classify_movie_duration)\n",
    "print(movie_db)\n"
   ],
   "id": "495c31a07ccfa6a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
       "3                 27000.0  448130642.0                  Action|Thriller  ...   \n",
       "4                   131.0          NaN                      Documentary  ...   \n",
       "\n",
       "  language country  content_rating       budget title_year  \\\n",
       "0  English     USA           PG-13  237000000.0     2009.0   \n",
       "1  English     USA           PG-13  300000000.0     2007.0   \n",
       "2  English      UK           PG-13  245000000.0     2015.0   \n",
       "3  English     USA           PG-13  250000000.0     2012.0   \n",
       "4      NaN     NaN             NaN          NaN        NaN   \n",
       "\n",
       "   actor_2_facebook_likes imdb_score aspect_ratio  movie_facebook_likes  \\\n",
       "0                   936.0        7.9         1.78                 33000   \n",
       "1                  5000.0        7.1         2.35                     0   \n",
       "2                   393.0        6.8         2.35                 85000   \n",
       "3                 23000.0        8.5         2.35                164000   \n",
       "4                    12.0        7.1          NaN                     0   \n",
       "\n",
       "  classified_duration  \n",
       "0                Long  \n",
       "1                Long  \n",
       "2                Long  \n",
       "3                Long  \n",
       "4                Long  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>classified_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### **Using `pipe`**\n",
    "1. **Pipeline on Titanic**\n",
    "   - Create a pipeline to:\n",
    "     - Filter passengers who survived (`Survived == 1`).\n",
    "     - Fill missing `Age` values with the mean.\n",
    "     - Create a new column, `Fare_Per_Age`, by dividing `Fare` by `Age`.\n"
   ],
   "id": "deda8e93bb5e3514"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T10:20:18.848139Z",
     "start_time": "2025-04-09T10:20:18.814545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_survivors(df):\n",
    "    \"\"\"filters the survived passengers\"\"\"\n",
    "    return df[df['Survived'] == 1]\n",
    "\n",
    "def fill_missing_age(df):\n",
    "    return df.assign(Age=df['Age'].fillna(df['Age'].mean()))\n",
    "def fare_per_age(df):\n",
    "    df['Fare_Per_Age'] = df['Fare'] / df['Age']\n",
    "    return df\n",
    "# Apply the pipeline\n",
    "result_df = (\n",
    "    df_titanic\n",
    "    .pipe(filter_survivors)\n",
    "    .pipe(fill_missing_age)\n",
    "    .pipe(fare_per_age)\n",
    ")\n",
    "print(result_df)"
   ],
   "id": "236fa522f6436104",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "..           ...       ...     ...   \n",
      "875          876         1       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "887          888         1       1   \n",
      "889          890         1       1   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked Age group  Fare_Per_Age  \n",
      "1        0          PC 17599  71.2833   C85        C     Adult      1.875876  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S     Adult      0.304808  \n",
      "3        0            113803  53.1000  C123        S     Adult      1.517143  \n",
      "8        2            347742  11.1333   NaN        S     Adult      0.412344  \n",
      "9        0            237736  30.0708   NaN        C     Child      2.147914  \n",
      "..     ...               ...      ...   ...      ...       ...           ...  \n",
      "875      0              2667   7.2250   NaN        C     Child      0.481667  \n",
      "879      1             11767  83.1583   C50        C     Adult      1.484970  \n",
      "880      1            230433  26.0000   NaN        S     Adult      1.040000  \n",
      "887      0            112053  30.0000   B42        S     Adult      1.578947  \n",
      "889      0            111369  30.0000  C148        C     Adult      1.153846  \n",
      "\n",
      "[342 rows x 14 columns]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. **Pipeline on Flights**\n",
    "   - Create a pipeline to:\n",
    "     - Filter flights with a departure delay greater than 30 minutes.\n",
    "     - Add a column `Delay_Per_Hour` by dividing the delay by the scheduled flight duration.\n"
   ],
   "id": "8fa7a09f18c0b542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def filter_long_delays(df):\n",
    "    \"\"\"filters long delays\"\"\"\n",
    "    return df[df['DepDelay'] > 30]\n",
    "\n",
    "\n",
    "def delay_per_hour(df):\n",
    "    \"\"\"adda a new column delay per hour\"\"\"\n",
    "    df = df.copy()\n",
    "    df['Delay_Per_Hour'] = df['DepDelay'] / df['Duration']\n",
    "    return df\n",
    "\n",
    "\n",
    "long_delay_flights = (\n",
    "    flights\n",
    "    .pipe(filter_long_delays)\n",
    "    .pipe(delay_per_hour)\n",
    ")\n",
    "\n",
    "print(long_delay_flights.head())"
   ],
   "id": "6b4a84ed1d4540f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2408d86ab8b406e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
